---
permalink: /
title: "Edward Fish, PhD"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello there! üëã

I'm Ed, a Senior Research Fellow at the Centre for Vision, Speech and Signal Processing (CVSSP) at the University of Surrey, where I work on computer vision for accessibility with [Professor Richard Bowden](https://www.surrey.ac.uk/people/richard-bowden) in the Cognitive Vision Group.

I recently completed my PhD in Efficient Multi-Modal Video Understanding, supervised by [Dr. Andrew Gilbert](https://www.surrey.ac.uk/people/andrew-gilbert). Currently I am focussed on research in Automated Sign Language Translation as part of the EPSRC project [**Sign GPT**](https://www.bbc.co.uk/news/articles/c4g9rd4g8w2o) alongside work on AI for efficient Sign Language Annotation funded by Google.org.

If you are interested in a PhD in a similar area, and are looking for a supervisor please get in touch for an informal chat. 

You can find my [publications](/publications/) and [CV](/cv/) here.

---

## üì¢ News
* **August 2025:** I obtained my BSL Level 101-103 certificate. Now studying towards level 2.
* **August 2025:** I'm chairing the BMVA one day symposium on AI for Sign Language Translation, Production, and Linguistics on December 10th. Register to present [here](https://www.bmva.org/meetings/25-12-10-Sign.html) 
* **July 2025:** Our paper, "VALLR: Visual ASR Language Model for Lip Reading", was accepted to **ICCV 2025**!
* **July 2025:** Our paper, "Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization", was accepted to **ICCV workshop - CLVL 2025** .
* **June 2025:** At **CVPR 2025** chairing the Sign Language Recognition, Recognition, Translation, and Production (SLRTP) workshop.
* **May 2025:** Code and paper for "Geo-Sign: Hyperbolic Contrastive Regularisation for Geometrically Aware Sign Language Translation" is available online [here](https://github.com/ed-fish/geo-sign)

---

## Current PhD Students

**Marshall Thomas**: "Integrating Non-Manual Features for Robust Sign Language Translation" (Co-Supervisor with Prof. Richard Bowden)

**[Karahan ≈ûahin](https://github.com/karahan-sahin)**: "Unified representations for Sign Language Translation and Production" (Co-Supervisor with Prof. Richard Bowden)


## üìù 2025 Publications

This is a selection of my recent work. For a complete list, please see my [publications page](/publications/).

<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    <div class="archive__item-thumb">
      <a href="/publications/2025-geo-sign"><img src="/images/geo-sign-thumb.jpg" alt="Thumbnail for Geo-Sign paper"></a>
    </div>
    <div class="archive__item-content">
      <h3 class="archive__item-title" itemprop="headline">
        <a href="/publications/2025-geo-sign">Geo-Sign: Hyperbolic Contrastive Regularisation for Geometrically-Aware Sign-Language Translation</a>
      </h3>
      <p class="archive__item-meta">Authors: <strong>E. Fish</strong>, R. Bowden</p>
      <p class="archive__item-excerpt" itemprop="description">Our pose-only method beats state-of-the-art pixel approaches by injecting hierarchical structure into a language model using hyperbolic geometry, setting new records on the CSL-Daily benchmark.</p>
    </div>
  </article>
</div>

<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    <div class="archive__item-thumb">
      <a href="/publications/2025-vallr"><img src="/images/vallr-thumb.jpg" alt="Thumbnail for VALLR paper on lip reading"></a>
    </div>
    <div class="archive__item-content">
      <h3 class="archive__item-title" itemprop="headline">
        <a href="/publications/2025-vallr">VALLR: Visual ASR Language Model for Lip Reading</a>
      </h3>
      <p class="archive__item-meta"><strong>ICCV 2025</strong></p>
      <p class="archive__item-meta">Authors: M. Thomas, <strong>E. Fish</strong>, R. Bowden.</p>
      <p class="archive__item-excerpt" itemprop="description">Achieves state-of-the-art results in lip reading with 99% less training data by deconstructing the problem into phoneme recognition and sentence reconstruction.</p>
    </div>
  </article>
</div>

<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    <div class="archive__item-thumb">
      <a href="/publications/2025-plot-tal"><img src="/images/plot-tal.png" alt="Thumbnail for PLOT TAL paper"></a>
    </div>
    <div class="archive__item-content">
      <h3 class="archive__item-title" itemprop="headline">
        <a href="/publications/2025-plot-tal">PLOT TAL: Prompt Learning with Optimal Transport for Few Shot Temporal Action Localization</a>
      </h3>
      <p class="archive__item-meta">Authors: <strong>E. Fish</strong>, A. Gilbert.</p>
        <p class="archive__item-meta"><strong>ICCV 2025</strong> (CLVL Workshop) </p>

      <p class="archive__item-excerpt" itemprop="description">A novel approach for few-shot temporal action localization, leveraging prompt learning and optimal transport.</p>
    </div>
  </article>
</div>

---


---

<p style="font-size: 0.8em; color: #666;">
  My chinese name is Ë¥πÂüÉÂæ∑ and my BSL sign name is Fish (thumb to chin variant).
</p>
